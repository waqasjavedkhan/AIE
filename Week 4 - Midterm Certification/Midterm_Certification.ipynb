{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aelydens/aie-resources/blob/main/AL_RAG_NVIDIA_10k_Filings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCn-Hjt4pHCH"
      },
      "source": [
        "# NVIDIA 10k Filings RAG with Langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp-YMyisozNq"
      },
      "source": [
        "Deliverables:\n",
        "\n",
        "Build üèóÔ∏è\n",
        "* Data: NVIDIA 10-k Filings\n",
        "* Model: OpenAI text-3-embedding small, GPT-3.5-turbo\n",
        "* Tooling: LangChain or LlamaIndex (you choose)\n",
        "* Vector Store: FAISS\n",
        "* Additional Component: Add one of the following: 1) visibility with WandB OR 2) evaluation with RAGAS\n",
        "Ship üö¢\n",
        "\n",
        "Evaluate your answers to the following questions\n",
        "* \"Who is the E-VP, Operations - and how old are they?\"\n",
        "* \"What is the gross carrying amount of Total Amortizable Intangible Assets for Jan 29, 2023?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "syOdjN1DKf9-"
      },
      "outputs": [],
      "source": [
        "#  installing the required packages and -qU for quiet and upgrade installation process\n",
        "!pip install -qU langchain langchain-core langchain-community langchain-openai pymupdf faiss_cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3vgbxsoKsHD",
        "outputId": "04358ea2-6d25-45f9-cdb4-2d007f5c38b0"
      },
      "outputs": [],
      "source": [
        "# importing required modules\n",
        "import os\n",
        "import getpass\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This line of code allows Jupyter Notebook to access the OpenAI API key securely without displaying it in the code.\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This line of code is setting the value of the environment variable \"WANDB_API_KEY\" to the result of the getpass.getpass() function.\n",
        "os.environ[\"WANDB_API_KEY\"] = getpass.getpass(\"WandB API Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This line of code is setting an environment variable named \"LANGCHAIN_WANDB_TRACING\" to the value \"true\".\n",
        "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BLzXyE0FPr-8"
      },
      "outputs": [],
      "source": [
        "# Initializing the OpenAI Embedding Model `text-embedding-3-small`.\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UwJLCbKcn-aq"
      },
      "outputs": [],
      "source": [
        "# Loading and spliting the document.\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = PyMuPDFLoader(\"https://d18rn0p25nwr6d.cloudfront.net/CIK-0001045810/1cbe8fe7-e08a-46e3-8dcc-b429fc06c1a4.pdf\")\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "chunks = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hUt1Ksj3OPZO"
      },
      "outputs": [],
      "source": [
        "# Setting up FAISS-powered vector store, and creating a retriever.\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "vector_store = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "retriever = vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sOB4J62xOcTg"
      },
      "outputs": [],
      "source": [
        "# Creating prompt using `ChatPromptTemplate`.\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'I don't know':\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4eNZsMZYOv1P"
      },
      "outputs": [],
      "source": [
        "# Initializing OpenAI Chat Model 'gpt-3.5-turbo' with a temperature of 0.\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "openai_chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xVI0AqBIOq-3"
      },
      "outputs": [],
      "source": [
        "# Creating LCEL chain.\n",
        "from operator import itemgetter\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": prompt | openai_chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sysadmin/anaconda3/envs/llmops-course/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwaqasjavedkhan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/sysadmin/llmops-course/AIE/Week 4 - Midterm Certification/wandb/run-20240311_062555-9m9utu7r</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/waqasjavedkhan/Midterm-Certification/runs/9m9utu7r' target=\"_blank\">royal-firefly-1</a></strong> to <a href='https://wandb.ai/waqasjavedkhan/Midterm-Certification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/waqasjavedkhan/Midterm-Certification' target=\"_blank\">https://wandb.ai/waqasjavedkhan/Midterm-Certification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/waqasjavedkhan/Midterm-Certification/runs/9m9utu7r' target=\"_blank\">https://wandb.ai/waqasjavedkhan/Midterm-Certification/runs/9m9utu7r</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/waqasjavedkhan/Midterm-Certification/runs/9m9utu7r?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7ff9793f0610>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importing the required modules, Creating a Retrieval Augmented QA Chain and initializing Weights & Biases project.\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "retrieval_augmented_qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(temperature=0.3),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        ")\n",
        "\n",
        "wandb.init(project=\"Midterm-Certification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LangChain activity to W&B at https://wandb.ai/waqasjavedkhan/AIE-Week%204%20-%20Midterm%20Certification/runs/1mz625m2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbTracer` is currently in beta.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `langchain`.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WARNING: Failed to serialize model: 'int' object is not subscriptable\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Debora Shoquist is the Executive Vice President of Operations at NVIDIA and is 69 years old.\n"
          ]
        }
      ],
      "source": [
        "# Running evaluation and logging the results.\n",
        "print(retrieval_augmented_qa_chain.run(\"Who is the E-VP, Operations - and how old are they?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WARNING: Failed to serialize model: 'int' object is not subscriptable\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The gross carrying amount of Total Amortizable Intangible Assets for Jan 29, 2023 is $3.539 billion.\n"
          ]
        }
      ],
      "source": [
        "# Running evaluation and logging the results.\n",
        "print(retrieval_augmented_qa_chain.run(\"What is the gross carrying amount of Total Amortizable Intangible Assets for Jan 29, 2023 in billions?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ad8d0dddb9648269ea648ed786459ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
          ]
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">royal-firefly-1</strong> at: <a href='https://wandb.ai/waqasjavedkhan/Midterm-Certification/runs/9m9utu7r' target=\"_blank\">https://wandb.ai/waqasjavedkhan/Midterm-Certification/runs/9m9utu7r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240311_062555-9m9utu7r/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Closing the logging.\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNOc30nsCbQCnUmXEA+s49Q",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
